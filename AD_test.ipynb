{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "408d8898-76fc-4ae6-a893-f57498a4da23",
   "metadata": {},
   "source": [
    "# Antibody Design -  test\n",
    "\n",
    "These are the rules to complete this test:\n",
    "\n",
    "- In this test, you will be asked to perform some analyses on antibody sequences using python, and return the results as a jupyter notebook in a git repository.\n",
    "- The test should not take more than a couple of hours to complete. You can use any tools on internet, but you can't receive any external help.\n",
    "- You should describe the protocol you have used to obtain the results, whenever it involves anything outside the jupyter notebook itself (e.g. databases, web tools, etc)\n",
    "- The results of the test will be discussed in the 2nd interview\n",
    "\n",
    "The sequence of the antibody we will analyse is the following:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52a1a8cd",
   "metadata": {},
   "source": [
    ">VH\n",
    "QVQLKESGPGLVAPSQSLSITCTVSGFPLTAYGVNWVRQPPGKGLEWLGMIWGDGNTDYNSALKSRLSISKDNSKSQVFLKMNSLQTDDTARYYCARDPYGSKPMDYWGQGTSVTVSS\n",
    ">VL\n",
    "DIVMSQSPSSLVVSVGEKVTMSCKSSQSLLYSSNQKNFLAWYQQKPGQSPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSVKAEDLAVYYCQQYFRYRTFGGGTKLEIKRA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07298bfe-1ed3-4526-868a-c8cce2abe6f5",
   "metadata": {},
   "source": [
    "__Q1__ Install the package anarci, and using it retrieve the following information:\n",
    "- germlines\n",
    "- CDR sequences\n",
    "- SHMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31c727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating csv for VH\n",
    "!ANARCI -i QVQLKESGPGLVAPSQSLSITCTVSGFPLTAYGVNWVRQPPGKGLEWLGMIWGDGNTDYNSALKSRLSISKDNSKSQVFLKMNSLQTDDTARYYCARDPYGSKPMDYWGQGTSVTVSS --assign_germline --outfile ABDesign_case --csv --scheme imgt\n",
    "\n",
    "# Creating csv for VL\n",
    "!ANARCI -i DIVMSQSPSSLVVSVGEKVTMSCKSSQSLLYSSNQKNFLAWYQQKPGQSPKLLIYWASTRESGVPDRFTGSGSGTDFTLTISSVKAEDLAVYYCQQYFRYRTFGGGTKLEIKRA --assign_germline --outfile ABDesiign_case --csv --scheme imgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading saved CSV\n",
    "df_VH = pd.read_csv(\"ABDesign_case_H.csv\")\n",
    "df_VL = pd.read_csv(\"ABDesign_case_KL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0640b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_VH = df_VH.iloc[:, 13:]\n",
    "aligned_VL = df_VL.iloc[:, 13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aebd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing overview of important information from the VH chain\n",
    "VH_info = dict(\n",
    "    v_gene=df_VH.v_gene.values[0],\n",
    "    j_gene=df_VH.j_gene.values[0],\n",
    "    CDR1=\"\".join(aligned_VH.iloc[:, 26:38].values.tolist()[0]),\n",
    "    CDR2=\"\".join(aligned_VH.iloc[:, 55:65].values.tolist()[0]),\n",
    "    CDR3=\"\".join(aligned_VH.iloc[:, 104:117].values.tolist()[0]),\n",
    ")\n",
    "VH_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8f0f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Providing overview of important information from the VL chain\n",
    "VL_info = dict(\n",
    "    v_gene=df_VL.v_gene.values[0],\n",
    "    j_gene=df_VL.j_gene.values[0],\n",
    "    CDR1=\"\".join(aligned_VL.iloc[:, 26:38].values.tolist()[0]),\n",
    "    CDR2=\"\".join(aligned_VL.iloc[:, 55:65].values.tolist()[0]),\n",
    "    CDR3=\"\".join(aligned_VL.iloc[:, 104:117].values.tolist()[0]),\n",
    ")\n",
    "VL_info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "543b78dc-d88c-4f60-9077-b1b4d4d478e0",
   "metadata": {},
   "source": [
    "__Q2__ write a function that returns all the occurrences of the motifs NG, DG, NS, and DS, if they overlap at least partially with any of the CDRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa2cb0-902e-447b-85e6-b7b4270a7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurences(sequence):\n",
    "    \"\"\"\n",
    "    A function that counts the occurences of overlapping motifs with any CDRs.\n",
    "\n",
    "    Assuming sequence is IMGT-numbered\n",
    "    \"\"\"\n",
    "    motifs = [\"NG\", \"DG\", \"NS\", \"DS\"]  # A list to look up motifs\n",
    "    motif_counts = dict(NG=0, DG=0, NS=0, DS=0)  # dict where we count each motif\n",
    "    for motif in motifs:\n",
    "        if motif in sequence[25:39].replace(\"-\", \"\"):\n",
    "            motif_counts[motif] += 1\n",
    "        if motif in sequence[54:66].replace(\"-\", \"\"):\n",
    "            motif_counts[motif] += 1\n",
    "        if motif in sequence[103:118].replace(\"-\", \"\"):\n",
    "            motif_counts[motif] += 1\n",
    "    return motif_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc5e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking occurences of motifs in light chain CDRs\n",
    "print(f\"Motifs in VL CDRs: {occurences(''.join(aligned_VL.values.tolist()[0]))}\")\n",
    "# Checking occurences of motifs in heavy chain CDRs\n",
    "print(f\"Motifs in VH CDRs: {occurences(''.join(aligned_VH.values.tolist()[0]))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f210873f",
   "metadata": {},
   "source": [
    "Only one overlapping or partialle overlapping motif in CDR was found in the heavy chain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "90098d78-4f56-4fdb-9b3c-7fdee431a91d",
   "metadata": {},
   "source": [
    "__Q3__ These sites are potential liabilities in the antibody. Using online tools, and your own intuition, describe which othese occurences might be problematic, which residues you would suggest mutating to eliminate such liabilities minimizing the risk of affecting the antibody binding affinity, and why"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a81da305",
   "metadata": {},
   "source": [
    "If the motifs are found at CDR regions it can affect binding. As CDRs are the ones that interact with antigen it is likely that a change in motif in these regions lead to poor affinity. Thus, I would suggest mutating residues in the framework regions to minimize risk affecting antibody binding affinity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a05c5b4d-ca2a-4839-98ab-642c2d92a802",
   "metadata": {},
   "source": [
    "__Q4__ Using the online tool ABodybuilder, build a 3d structure for this antibody. On the structure, using pymol or any python library of your choice (e.g. BioPDB) identify the minimal distance between any atom of any residue in the CDR3 of the heavy and light chains. You will need to report the residue in the CDR3 of the havy chain and the atom, the residue in the CDFR3 of the light chain and the atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45022a8e-e258-46f9-8dcf-eb9e98c576cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB.PDBParser import PDBParser\n",
    "\n",
    "parser = PDBParser(PERMISSIVE=True)\n",
    "structure_id = \"ABDesign_case_rank1_imgt_scheme\"\n",
    "filename = \"ABDesign_case_rank1_imgt_scheme.pdb\"\n",
    "model = parser.get_structure(structure_id, filename)[0]\n",
    "chainH = model[\"H\"]\n",
    "chainL = model[\"L\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I chose CA of residue 114 of the heavy chain and calculated its distance to the CA of residue 107 in the light chain\n",
    "chainH[114][\"CA\"] - chainL[107][\"CA\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a14d2b0-b45e-4f76-b9f8-eb5501a782f0",
   "metadata": {},
   "source": [
    "__Q5__ A library was constructed on the antibody by introducing variability in the CDR3 of the heavy chain, and the binding affinity was measured for each antibody in the library. The affinities are reported as -log10, so the higher values indicate the stronger binders. Can you provide the code to train an XGboost model on the train_data using the techniques you deem necessary to ensure the model robustness, and use it to predict the binding affinity of the antibody in the list _test_\n",
    "Report the model performance in terms of RMSE, the predicted values for the test antibodies, and any comment on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9ed3b-dcc0-444d-81c7-1f7f8e5496d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Define the number of data points\n",
    "n_samples = 1000\n",
    "\n",
    "# Define possible amino acids\n",
    "amino_acids = list(\"ARNDCEQGHILKMFPSTWYV\")\n",
    "\n",
    "\n",
    "# Generate random CDR3 sequences\n",
    "def generate_CDR3(length):\n",
    "    return \"\".join(random.choice(amino_acids) for _ in range(length))\n",
    "\n",
    "\n",
    "CDR3_sequences = [generate_CDR3(np.random.randint(15, 20)) for _ in range(n_samples)]\n",
    "\n",
    "# Generate random scores between 0 and 10\n",
    "scores = np.random.uniform(6, 10, n_samples)\n",
    "\n",
    "# Create dataset\n",
    "train_data = list(zip(CDR3_sequences, scores))\n",
    "\n",
    "test_data = [\n",
    "    \"KYWRDGSTWWELIYGYG\",\n",
    "    \"RQSFKFCCTFE\",\n",
    "    \"LLWRYFFRKFSCD\",\n",
    "    \"STLTFSDNIGSYPCWD\",\n",
    "    \"QRLQEHTAGRG\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec96202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sapiens\n",
    "\n",
    "\n",
    "def get_sapiens_embedding(sequences):\n",
    "    embs = []\n",
    "    for seq in sequences:\n",
    "        emb = sapiens.predict_sequence_embedding(seq, \"H\", layer=None)\n",
    "        embs.append(emb)\n",
    "    return np.array(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = get_sapiens_embedding(CDR3_sequences)\n",
    "test_embeddings = get_sapiens_embedding(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4153c86",
   "metadata": {},
   "source": [
    "I perform gridsearch and kfold cross validation in this case since the sequences are generated by random selection from the amino acids at random lengths. If these were real CDR3 sequences, I would expect more conservation at certain residues and would probably use something like a stratified k-fold CV to group similar sequences into the same fold. I want to predict how each of these mutations affect binding affinity and it will be harder for the model to learn if grouped randomly as in normal K-fold\n",
    "\n",
    "Below I use the sklearn and a XGboost regressor to predict BA. I perform gridsearch over max depth of the tree, number of estimators and the embedding layers in the sapiens embeddings. I use Sapiens to model the sequences and obtain sequence embeddings. These are then scaled prior to PCA followed by fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce763d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import make_scorer\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Defining RMSE loss function\n",
    "def rmse(actual, predicted):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "    difference = predicted - actual\n",
    "    squared_difference = difference**2\n",
    "    mean_squared_difference = squared_difference.mean()\n",
    "    rmse = np.sqrt(mean_squared_difference)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "# Wrap the scorer to be used with sklearn\n",
    "scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "\n",
    "# Defining a base estimator to extract a given layer\n",
    "class sapiens_embeddings(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, layer=None):\n",
    "        self.layer = layer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        emb = X[:, self.layer, :]\n",
    "        return emb\n",
    "\n",
    "\n",
    "# Defining XGBRegressor\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Defining a pipleline starting with obtaining the given embeddings, then scaling, then PCA and are then fed to the model\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"embeddings\", sapiens_embeddings()),\n",
    "        (\"scale\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=0.95)),\n",
    "        (\"model\", xgb_model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define gridsearch using the pipeline and providing the parameters to search\n",
    "clf = GridSearchCV(\n",
    "    pipe,\n",
    "    {\n",
    "        \"embeddings__layer\": range(5),\n",
    "        \"model__max_depth\": [2, 4, 6],\n",
    "        \"model__n_estimators\": [100, 200, 400, 800],\n",
    "    },\n",
    "    verbose=1,\n",
    "    scoring=scorer,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(train_embeddings, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting best results\n",
    "mean_score = clf.cv_results_[\"mean_test_score\"][clf.best_index_]\n",
    "print(f\"Best parameters: {clf.best_params_}\")\n",
    "print(f\"RMSE Mean CV score: {mean_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5ff58a3",
   "metadata": {},
   "source": [
    "Visualizing train predictions vs true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_y_pred = clf.predict(train_embeddings)\n",
    "plt.scatter(train_y_pred, scores)\n",
    "plt.xlim(5, 11)\n",
    "plt.ylim(5, 11)\n",
    "plt.xlabel(\"Predicted BA\")\n",
    "plt.ylabel(\"True BA\")\n",
    "plt.title(\"True vs Predicted BA's\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79330414",
   "metadata": {},
   "source": [
    "A linear trend is observed but predictions comes with high uncertainty."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b714f97",
   "metadata": {},
   "source": [
    "Now I predict the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26602e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(test_embeddings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
